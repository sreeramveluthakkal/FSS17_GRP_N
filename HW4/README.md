# FSS17_GRP_N
## HW3 - Regression Trees

### Description
Building a regression tree learner:

Apply supervised Discretization
At each level of the tree, break the data on the ranges and find the column whose breaks most reduces the variability of the target variable (we will use dom).
For each break, apply the regression tree learner recursively.
Recursion stops when the breaks do not improve the supervised target score, when there are tooFew examples to break, or when the tree depth is too much.
Write a list printer that recurses down the tree and prints details about each node, indented by its level in tree.

Test: run your decision tree learner on auto.csv. Using dom and tooFew is 10, the auto.csv divides into something like this:

### Files
`d.py` - python code for HW3   
`output.txt` - Table generated by the code in b.py sorted by domination rank  

### Dependencies
`Python 2.7`

### Building
`python d.py <inputfile> <column index> <small value>`  
For example `python d.py auto.csv 1` (default value of cohen used is 0.2. Read Note below)
(or) For example `python d.py auto.csv 1 .1`  
NOTE:
Column index starts from 0.
The last argument is optional and is the 'cohen' i.e. the multiplier for standard deviation in calculating epsilon.

The following output looks at the second column - displacement - in auto.csv. The 'median' is the median of the domination ranks of the corresponding bins. The cohen used is the default value of 0.2.
`python d.py auto.csv 1`

### Sample Output
  

### Contributors
Aswin Anil Kumar,  
Seyedsamim Mirhosseini Ghamsari,  
Sreeram Veluthakkal
